{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Class, for use in pipelines, to select certain columns from a DataFrame and convert to a numpy array\n",
    "# From A. Geron: Hands-On Machine Learning with Scikit-Learn & TensorFlow, O'Reilly, 2017\n",
    "# Modified by Derek Bridge to allow for casting in the same ways as pandas.DataFrame.astype\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values\n",
    "    \n",
    "# Class, for use in pipelines, to binarize nominal-valued features (while avoiding the dummy variable trap)\n",
    "# By Derek Bridge, 2017\n",
    "class FeatureBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_values):\n",
    "        self.features_values = features_values\n",
    "        self.num_features = len(features_values)\n",
    "        self.labelencodings = [LabelEncoder().fit(feature_values) for feature_values in features_values]\n",
    "        self.onehotencoder = OneHotEncoder(sparse=False,\n",
    "            n_values=[len(feature_values) for feature_values in features_values])\n",
    "        self.last_indexes = np.cumsum([len(feature_values) - 1 for feature_values in self.features_values])\n",
    "    def fit(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        return self.onehotencoder.fit(X)\n",
    "    def transform(self, X, y=None):\n",
    "        for i in range(0, self.num_features):\n",
    "            X[:, i] = self.labelencodings[i].transform(X[:, i])\n",
    "        onehotencoded = self.onehotencoder.transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def fit_transform(self, X, y=None):\n",
    "        onehotencoded = self.fit(X).transform(X)\n",
    "        return np.delete(onehotencoded, self.last_indexes, axis=1)\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"features_values\" : self.features_values}\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            self.setattr(parameter, value)\n",
    "        return self\n",
    "\n",
    "# similar to CS4618, but plays nice with cross_val_score\n",
    "# for some reason, in cross_val_score, it didn't like the inheritance from Imputer class\n",
    "class MissingNominalImputer:\n",
    "    def __init__(self, missing_values, strategy):\n",
    "        self.missing_values = missing_values\n",
    "        self.strategy = strategy\n",
    "        if(self.missing_values not in ['NaN','nan']):\n",
    "                print(\"MissingNominalImputer can't deal with not NaN values\")\n",
    "    def fit(self, X, y=None):\n",
    "        if self.strategy == \"most_frequent\":\n",
    "            self.fills = pd.DataFrame(X).mode(axis=0).squeeze() \n",
    "            return self\n",
    "        else:\n",
    "            print('ERROR AT MISSING_NOMINAL_IMPUTER')\n",
    "    def transform(self, X):\n",
    "        if hasattr(self, \"fills\"):\n",
    "            return pd.DataFrame(X).fillna(self.fills).values\n",
    "        else:\n",
    "            print('ERROR AT MISSING_NOMINAL_IMPUTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing a new feature, the number of true statements and outputing a df.describe(), I saw that the minimum of number of true statements was -1 (it is leakage, but I deleted that feature after, it was for testing purposes).\n",
    "\n",
    "After a lot of debugging I found a particular example:\n",
    ">1606\tmostly-true\t\"Hospitals, doctors, MRIs, surgeries and so forth are more extensively used and far more expensive in this country than they are in many other countries.''\thealth-care\tmitt-romney\tFormer governor\tMassachusetts\trepublican\t34\t32\t58\t33\t19\ta Fox News Sunday interview  \n",
    "\n",
    "The problem: \"some text'', at closing, instead of double quotes, two single quotes were used. By default, read_csv considers a text between two double quotes as a token, and in our case another \" used for matching was only some rows below.\n",
    "\n",
    "We need not to consider a token between quotes, so the parameter quoting must be set to csv.QUOTE_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, read the data\n",
    "#it is a tab separated file, so sep argument is a tab\n",
    "#take care at quotes, some end in '' instead of \"\n",
    "df = pd.read_csv(\"dataset_statements.tsv\", sep = '\\t', quoting = csv.QUOTE_NONE)\n",
    "\n",
    "#also shuffle the data and reset index (better safe than sorry)\n",
    "df = df.take(np.random.permutation(len(df)))\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12836, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'subject', 'speaker', 'job', 'state',\n",
       "       'party', 'num_barely_trues', 'num_falses', 'num_half_trues',\n",
       "       'num_mostly_trues', 'num_pants_fires', 'location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   int64\n",
       "label               object\n",
       "statement           object\n",
       "subject             object\n",
       "speaker             object\n",
       "job                 object\n",
       "state               object\n",
       "party               object\n",
       "num_barely_trues     int64\n",
       "num_falses           int64\n",
       "num_half_trues       int64\n",
       "num_mostly_trues     int64\n",
       "num_pants_fires      int64\n",
       "location            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>num_barely_trues</th>\n",
       "      <th>num_falses</th>\n",
       "      <th>num_half_trues</th>\n",
       "      <th>num_mostly_trues</th>\n",
       "      <th>num_pants_fires</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635</td>\n",
       "      <td>true</td>\n",
       "      <td>\"Just this week we received the news that for ...</td>\n",
       "      <td>social-security</td>\n",
       "      <td>marco-rubio</td>\n",
       "      <td>U.S. Senator</td>\n",
       "      <td>Florida</td>\n",
       "      <td>republican</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>a U.S. Senate primary debate on FOX News Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7214</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>Hurricane Sandy, the most destructive Atlantic...</td>\n",
       "      <td>climate-change,environment,weather</td>\n",
       "      <td>environment-new-jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an online post about global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10285</td>\n",
       "      <td>true</td>\n",
       "      <td>At the 50 Milwaukee schools serving at least 8...</td>\n",
       "      <td>education</td>\n",
       "      <td>alberta-darling</td>\n",
       "      <td>State Senator, 8th District</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>an interview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        label                                          statement  \\\n",
       "0   1635         true  \"Just this week we received the news that for ...   \n",
       "1   7214  barely-true  Hurricane Sandy, the most destructive Atlantic...   \n",
       "2  10285         true  At the 50 Milwaukee schools serving at least 8...   \n",
       "\n",
       "                              subject                 speaker  \\\n",
       "0                     social-security             marco-rubio   \n",
       "1  climate-change,environment,weather  environment-new-jersey   \n",
       "2                           education         alberta-darling   \n",
       "\n",
       "                           job       state       party  num_barely_trues  \\\n",
       "0                 U.S. Senator     Florida  republican                33   \n",
       "1                          NaN  New Jersey        none                 1   \n",
       "2  State Senator, 8th District   Wisconsin  republican                 1   \n",
       "\n",
       "   num_falses  num_half_trues  num_mostly_trues  num_pants_fires  \\\n",
       "0          24              32                35                5   \n",
       "1           0               0                 0                0   \n",
       "2           1               2                 1                1   \n",
       "\n",
       "                                          location  \n",
       "0  a U.S. Senate primary debate on FOX News Sunday  \n",
       "1              an online post about global warming  \n",
       "2                                     an interview  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the column meaning, it is clear that 'id' has no relation to the statement, so this column should be deleted.\n",
    "\n",
    "The data types of the columns look ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12836, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clear 'id' feature\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>num_barely_trues</th>\n",
       "      <th>num_falses</th>\n",
       "      <th>num_half_trues</th>\n",
       "      <th>num_mostly_trues</th>\n",
       "      <th>num_pants_fires</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12836</td>\n",
       "      <td>12836</td>\n",
       "      <td>12836</td>\n",
       "      <td>12836</td>\n",
       "      <td>9261</td>\n",
       "      <td>10084</td>\n",
       "      <td>12836</td>\n",
       "      <td>12836.000000</td>\n",
       "      <td>12836.000000</td>\n",
       "      <td>12836.000000</td>\n",
       "      <td>12836.000000</td>\n",
       "      <td>12836.000000</td>\n",
       "      <td>12707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>12810</td>\n",
       "      <td>4547</td>\n",
       "      <td>3318</td>\n",
       "      <td>1360</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>half-true</td>\n",
       "      <td>On a cap-and-trade plan.</td>\n",
       "      <td>health-care</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2638</td>\n",
       "      <td>3</td>\n",
       "      <td>475</td>\n",
       "      <td>616</td>\n",
       "      <td>620</td>\n",
       "      <td>1263</td>\n",
       "      <td>5687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.595980</td>\n",
       "      <td>13.369975</td>\n",
       "      <td>17.218838</td>\n",
       "      <td>16.526955</td>\n",
       "      <td>6.246261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.996727</td>\n",
       "      <td>24.150879</td>\n",
       "      <td>35.910604</td>\n",
       "      <td>36.225691</td>\n",
       "      <td>16.162788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                 statement      subject       speaker  \\\n",
       "count       12836                     12836        12836         12836   \n",
       "unique          6                     12810         4547          3318   \n",
       "top     half-true  On a cap-and-trade plan.  health-care  barack-obama   \n",
       "freq         2638                         3          475           616   \n",
       "mean          NaN                       NaN          NaN           NaN   \n",
       "std           NaN                       NaN          NaN           NaN   \n",
       "min           NaN                       NaN          NaN           NaN   \n",
       "25%           NaN                       NaN          NaN           NaN   \n",
       "50%           NaN                       NaN          NaN           NaN   \n",
       "75%           NaN                       NaN          NaN           NaN   \n",
       "max           NaN                       NaN          NaN           NaN   \n",
       "\n",
       "              job  state       party  num_barely_trues    num_falses  \\\n",
       "count        9261  10084       12836      12836.000000  12836.000000   \n",
       "unique       1360     85          24               NaN           NaN   \n",
       "top     President  Texas  republican               NaN           NaN   \n",
       "freq          620   1263        5687               NaN           NaN   \n",
       "mean          NaN    NaN         NaN         11.595980     13.369975   \n",
       "std           NaN    NaN         NaN         18.996727     24.150879   \n",
       "min           NaN    NaN         NaN          0.000000      0.000000   \n",
       "25%           NaN    NaN         NaN          0.000000      0.000000   \n",
       "50%           NaN    NaN         NaN          2.000000      2.000000   \n",
       "75%           NaN    NaN         NaN         12.000000     15.000000   \n",
       "max           NaN    NaN         NaN         70.000000    114.000000   \n",
       "\n",
       "        num_half_trues  num_mostly_trues  num_pants_fires        location  \n",
       "count     12836.000000      12836.000000     12836.000000           12707  \n",
       "unique             NaN               NaN              NaN            5161  \n",
       "top                NaN               NaN              NaN  a news release  \n",
       "freq               NaN               NaN              NaN             310  \n",
       "mean         17.218838         16.526955         6.246261             NaN  \n",
       "std          35.910604         36.225691        16.162788             NaN  \n",
       "min           0.000000          0.000000         0.000000             NaN  \n",
       "25%           0.000000          0.000000         0.000000             NaN  \n",
       "50%           3.000000          3.000000         1.000000             NaN  \n",
       "75%          13.000000         12.000000         5.000000             NaN  \n",
       "max         160.000000        163.000000       105.000000             NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have a look at every individual feature\n",
    "\n",
    " * label - no missing values, is the target class\n",
    " * statement\n",
    "     * no missing values\n",
    "     * has some duplicates, I don't think it is wrong\n",
    "     * free form text\n",
    " * subject - no missing values, set-valued feature\n",
    " * speaker - no missing values, nominal-valued feature\n",
    " * job\n",
    "     * lots of missing values\n",
    "     * should not drop column, since some jobs involve more hiding of truth\n",
    "     * will input mode in pipeline\n",
    "     * nominal-valued feature\n",
    " * state\n",
    "     * lots of missing values\n",
    "     * will input mode in pipeline\n",
    "     * nominal-valued feature\n",
    " * party - no missing values, nominal-valued feature\n",
    " * num_barely_trues, num_falses, num_half_trues, num_mostly_trues, num_pants_fires\n",
    "     * no missing values\n",
    "     * contain information about the whole dataset, that is **leakage**; so they should be dropped\n",
    "     * numeric-valued features\n",
    " * location\n",
    "     * few missing examples\n",
    "     * should drop those examples\n",
    "     * nominal-valued feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should check for good intentions of those who made the data, maybe instead of leaving 2 tabs for missing value they wrote ? or UNK or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job  has  none  for  4 examples\n",
      "party  has  none  for  2185 examples\n"
     ]
    }
   ],
   "source": [
    "features = ['statement', 'subject', 'speaker', 'job', 'state', 'party', 'location']\n",
    "for col in features:\n",
    "    l = df[col].unique()\n",
    "    for val in ['?', 'N/A', 'UNK', 'n/a', 'unk', 'NaN', 'nan', 'none']:\n",
    "        if val in l:\n",
    "            print(col, ' has ', val, ' for ', (df[col]==val).sum(), 'examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Party feature could have none because they are not affiliated to any parties.  \n",
    "Job also could be none, so it's not wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12707, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing location\n",
    "df.dropna(subset = ['location'], inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12707, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns with leakage\n",
    "leak_col = ['num_barely_trues', 'num_falses', 'num_half_trues', 'num_mostly_trues', 'num_pants_fires']\n",
    "for col in leak_col:\n",
    "    df.drop(col, axis = 1, inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of classifiers\n",
    "\n",
    "I've used stratified-k-fold-cross-validation because the test data is not so big (only 12 thousand examples).\n",
    "Holdout does not reuse values for training and testing, so we use k-fold. Since we want the distribution of examples with respect to labels to be the same in test set and in training set, I used stratified k-fold.\n",
    "\n",
    "When _k=10_, the number of examples in each fold is ~1200, so there are enough for testing and for training.\n",
    "\n",
    "For comparing different classifiers, I use the following:\n",
    " * confusion matrix\n",
    " * accuracy (could also be seen out of confusion matrix)\n",
    " * recall - shows the ability of classifier to find positive examples; when used in multilabel classification and with average parameter = 'macro', it computes this score for each label and returns the mean\n",
    " \n",
    "source for recall https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"].values\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "label_domain = ['pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true']\n",
    "labels_encoded_ord = encoder.transform(label_domain)\n",
    "#labels_encoded_ord is used for ordering the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the confusion matrix, accuracy and recall for a pipeline, evaluated using stratified k-fold\n",
    "def evaluate(pipeline_name, pipeline, df = df, y_encoded = y_encoded, cv = 10):  \n",
    "    y_predicted = cross_val_predict(pipeline, df, y_encoded, cv=cv)\n",
    "\n",
    "    print(pd.DataFrame(confusion_matrix(y_encoded, y_predicted, labels = labels_encoded_ord), \n",
    "                       index = label_domain, columns = label_domain))\n",
    "    print(pipeline_name, ' accuracy: ', accuracy_score(y_encoded, y_predicted))\n",
    "    print(pipeline_name, ' recall:   ', recall_score(y_encoded, y_predicted, average = 'macro'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build the majority-class classifier so we have a refference point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire            0      0            0       1035            0     0\n",
      "false                 0      0            0       2486            0     0\n",
      "barely-true           0      0            0       2091            0     0\n",
      "half-true             0      0            0       2615            0     0\n",
      "mostly-true           0      0            0       2444            0     0\n",
      "true                  0      0            0       2036            0     0\n",
      "Majority-class classifier:   accuracy:  0.20579208310380107\n",
      "Majority-class classifier:   recall:    0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "df['dummy'] = 1 #need a numerical feature for the dummyClassifier, we dropped all from dataset already\n",
    "\n",
    "maj_pipeline = Pipeline([(\"selector\", DataFrameSelector(['dummy'])), \n",
    "                         (\"estimator\", DummyClassifier(strategy = \"most_frequent\"))])\n",
    "\n",
    "evaluate('Majority-class classifier: ', maj_pipeline)\n",
    "\n",
    "#drop the dummy column\n",
    "df.drop('dummy', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will make a basic classifier which takes into account all features and uses a TfidfVectorizer for the 'statement'.\n",
    "For encoding the 'subject', since it is a set-valued feature, a CountVectorizer will do the job but it is needed a different regex (words can be hyphenated as in \"job-accomplishments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "nominal_features = ['speaker', 'job', 'state', 'party', 'location']\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"imputer\", MissingNominalImputer(missing_values=\"nan\", strategy=\"most_frequent\")), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].dropna().unique() for feature in nominal_features]))\n",
    "        ])\n",
    "\n",
    "#need a count vectorizer for set-valued feature\n",
    "sbj_pipeline = Pipeline([(\"selector\", DataFrameSelector('subject')), \n",
    "                        (\"vectorizer\", CountVectorizer(token_pattern = '(?u)\\\\b[^,]+\\\\b'))\n",
    "                         ])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector('statement')),\n",
    "        (\"vectorizer\", TfidfVectorizer(stop_words = 'english'))\n",
    "        ])\n",
    "\n",
    "union_step = (\"union\", FeatureUnion([(\"nominal_pipeline\", nominal_pipeline),\n",
    "                                     (\"sbj_pipeline\", sbj_pipeline),\n",
    "                                     (\"text_pipeline\", text_pipeline)\n",
    "                                    ]))\n",
    "\n",
    "ovr_pipeline = Pipeline([union_step,            \n",
    "                         (\"estimator\", LogisticRegression())\n",
    "                        ])\n",
    "\n",
    "cent_pipeline = Pipeline([union_step,\n",
    "                          (\"estimator\", LogisticRegression(multi_class = \"multinomial\", solver = \"newton-cg\"))\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire          229    322          151        172           93    68\n",
      "false               162    750          385        483          395   311\n",
      "barely-true          77    520          389        534          361   210\n",
      "half-true            56    496          387        708          638   330\n",
      "mostly-true          44    372          279        635          685   429\n",
      "true                 29    361          177        451          544   474\n",
      "One-vs-rest  accuracy:  0.2545840875108208\n",
      "One-vs-rest  recall:    0.248802374992091\n",
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire          234    318          158        163           95    67\n",
      "false               165    738          393        485          392   313\n",
      "barely-true          82    514          401        524          357   213\n",
      "half-true            61    477          403        705          631   338\n",
      "mostly-true          46    370          293        636          669   430\n",
      "true                 30    350          187        443          540   486\n",
      "Cross-entropy  accuracy:  0.25442669394821754\n",
      "Cross-entropy  recall:    0.24945950910303338\n"
     ]
    }
   ],
   "source": [
    "evaluate('One-vs-rest', ovr_pipeline)\n",
    "evaluate('Cross-entropy', cent_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look too promising, only for recall score an improvement is seen from the dummy classifier. No advantage is seen for using the cross-entropy function over the one-vs-rest approact.  \n",
    "I will use less features and set parameters for the TfidfVectorizer, we may have the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire          201    264           89        367           79    35\n",
      "false                97    614          247        973          367   188\n",
      "barely-true          47    484          223        848          358   131\n",
      "half-true            33    453          226       1131          560   212\n",
      "mostly-true          25    384          170       1033          563   269\n",
      "true                 16    320          130        840          514   216\n",
      "One-vs-rest  accuracy:  0.23199811127724876\n",
      "One-vs-rest  recall:    0.219464793311105\n"
     ]
    }
   ],
   "source": [
    "nominal_features = ['speaker']\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"imputer\", MissingNominalImputer(missing_values=\"nan\", strategy=\"most_frequent\")), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].dropna().unique() for feature in nominal_features])),\n",
    "        ])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector('statement')),\n",
    "        (\"vectorizer\", TfidfVectorizer(stop_words = 'english', max_df = 0.8, min_df = 0.2))\n",
    "        ])\n",
    "\n",
    "union_step = (\"union\", FeatureUnion([(\"nominal_pipeline\", nominal_pipeline),\n",
    "                                     (\"text_pipeline\", text_pipeline)\n",
    "                                    ]))\n",
    "\n",
    "ovr_pipeline = Pipeline([ union_step,            \n",
    "                        (\"estimator\", LogisticRegression())\n",
    "                        ])\n",
    "\n",
    "evaluate('One-vs-rest', ovr_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like an improvement.  \n",
    "Another idea is to add new features. From the labeled training set, we could compute for each label and each speaker the ratio of pants-fire, false, .. , true statetents with respect to total number of speaker's statenemts.  \n",
    "For this, we need a step in pipeline which given the dataset will return the numpy 2d array with those ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the label_col_name must be last value in grouping list\n",
    "class AddNumericColumnsRatios:\n",
    "    def __init__(self, label_col_name = 'label', label_domain = label_domain, grouping = ['speaker', 'label']):\n",
    "        self.label_domain = label_domain\n",
    "        self.label_col_name = label_col_name\n",
    "        self.grouping = grouping\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        #ensure all labels are in the dataset by adding a dummy speaker with all possible label values\n",
    "        X_au = X\n",
    "        for val in self.label_domain:\n",
    "            X_au = X_au.append({'speaker' : '__xzasdf__', 'label' : val}, ignore_index=True)\n",
    "        \n",
    "        #count number of occurences of each label for each speaker\n",
    "        #next code line is adapted from https://stackoverflow.com/questions/37003100/pandas-groupby-for-zero-values, https://stackoverflow.com/questions/37077898/pandas-dataframe-how-to-add-column-with-number-of-occurrences-in-other-column\n",
    "        self.cnt = X_au.groupby(self.grouping)[self.label_col_name].count().unstack(fill_value = 0).stack()\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        res = X.apply(lambda x: self.cnt[x['speaker']] if x['speaker'] in self.cnt.index \n",
    "                      else pd.Series({'barely-true':1, 'false':1, 'half-true':1, 'mostly-true':1, 'pants-fire':1, 'true':1})\n",
    "                      , axis = 1)#assume equal probability for each statement for speakers not known\n",
    "        \n",
    "        res['total'] = 0\n",
    "        \n",
    "        #make total number of statements\n",
    "        for val in self.label_domain :\n",
    "            res['total'] += res[val]\n",
    "        \n",
    "        #divide each statement by the total number of statements\n",
    "        for val in self.label_domain :\n",
    "            res[val] /= res['total']\n",
    "        \n",
    "        #erase the additional 'total' column\n",
    "        res.drop('total', axis=1, inplace=True)\n",
    "        \n",
    "        #return np array\n",
    "        return res.values\n",
    "    \n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a SGDClassifier with a different penalty function and bigger alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire          418    232          131        140           58    56\n",
      "false               618    530          364        389          307   278\n",
      "barely-true         433    399          369        354          309   227\n",
      "half-true           542    377          352        489          503   352\n",
      "mostly-true         460    330          285        482          474   413\n",
      "true                419    286          222        325          403   381\n",
      "Ratios pipeline  accuracy:  0.2094121350436767\n",
      "Ratios pipeline  recall:    0.22693388006938853\n"
     ]
    }
   ],
   "source": [
    "# The features we want to select\n",
    "ratios_pip = Pipeline([(\"ratios_numeric\", AddNumericColumnsRatios())])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector('statement')),\n",
    "        (\"vectorizer\", TfidfVectorizer(stop_words = 'english'))\n",
    "        ])\n",
    "\n",
    "pipeline_ratios = Pipeline([(\"union\", FeatureUnion([(\"ratios_pipeline\", ratios_pip),\n",
    "                                                    (\"text_pipeline\", text_pipeline)\n",
    "                                            ])),\n",
    "            (\"classifier\", SGDClassifier(penalty='l1', alpha=4e-3, max_iter=1000))                            \n",
    "                           ])\n",
    "\n",
    "evaluate('Ratios pipeline', pipeline_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we ignored too many features and considered the label ratios to be more meaningful than they are. But most probably the parameters for SGDClassifier were not good.\n",
    "We should now try to use a CountVectorizer instead of a TfidVecetorizer and try to change the solver for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire          254    292          158        154           87    90\n",
      "false               217    680          404        452          382   351\n",
      "barely-true         129    476          407        468          354   257\n",
      "half-true           116    482          447        618          594   358\n",
      "mostly-true          76    404          325        578          602   459\n",
      "true                 77    373          251        394          468   473\n",
      "With count vectorizer  accuracy:  0.2387660344691902\n",
      "With count vectorizer  recall:    0.23809179540110023\n"
     ]
    }
   ],
   "source": [
    "# The features we want to select\n",
    "nominal_features = ['job', 'state', 'party', 'location']\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"imputer\", MissingNominalImputer(missing_values=\"nan\", strategy=\"most_frequent\")), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].dropna().unique() for feature in nominal_features]))\n",
    "        ])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector('statement')),\n",
    "        (\"vectorizer\", CountVectorizer(stop_words = 'english'))\n",
    "        ])\n",
    "\n",
    "union_step = (\"union\", FeatureUnion([(\"nominal_pipeline\", nominal_pipeline),\n",
    "                                     (\"sbj_pipeline\", sbj_pipeline),\n",
    "                                     (\"ratios_pipeline\", ratios_pip),\n",
    "                                     (\"text_pipeline\", text_pipeline)\n",
    "                                    ]))\n",
    "\n",
    "cent_pipeline = Pipeline([union_step,\n",
    "                          (\"estimator\", LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\"))\n",
    "                        ])\n",
    "\n",
    "evaluate(\"With count vectorizer\", cent_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pants-fire  false  barely-true  half-true  mostly-true  true\n",
      "pants-fire           33    483           29        350          112    28\n",
      "false                 8    982           77        851          481    87\n",
      "barely-true           6    709           81        812          422    61\n",
      "half-true             6    676           78       1086          689    80\n",
      "mostly-true           4    555           53        950          768   114\n",
      "true                  0    465           48        795          612   116\n",
      "With count vectorizer  accuracy:  0.24128433147084286\n",
      "With count vectorizer  recall:    0.2086905585203386\n"
     ]
    }
   ],
   "source": [
    "# The features we want to select\n",
    "nominal_features = ['speaker', 'job', 'state']\n",
    "\n",
    "nominal_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector(nominal_features)), \n",
    "        (\"imputer\", MissingNominalImputer(missing_values=\"nan\", strategy=\"most_frequent\")), \n",
    "        (\"binarizer\", FeatureBinarizer([df[feature].dropna().unique() for feature in nominal_features]))\n",
    "        ])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        (\"selector\", DataFrameSelector('statement')),\n",
    "        (\"vectorizer\", CountVectorizer(min_df = 0.3))\n",
    "        ])\n",
    "\n",
    "union_step = (\"union\", FeatureUnion([(\"nominal_pipeline\", nominal_pipeline),\n",
    "                                     (\"text_pipeline\", text_pipeline)\n",
    "                                    ]))\n",
    "\n",
    "cent_pipeline = Pipeline([union_step,\n",
    "                          (\"classifier\", SGDClassifier(loss = \"log\", alpha = 0.01, max_iter = 1000))])\n",
    "\n",
    "evaluate(\"With count vectorizer\", cent_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "The best classifiers were the first ones, which took into account all features.  \n",
    "Computing ratio of each label for speakers did not help very much. Neither changing the solvers and TfIdfVectorizer with CountVectorizer did much difference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
